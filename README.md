# cnts_messaging_svc\n\nA messaging service implementation providing publish-subscription functionality with FastAPI. This service handles message persistence, real-time subscriptions, and historical message fetching with a sophisticated composite primary key design and environment-specific auto-increment mechanisms.\n\n## Table of Contents\n\n- [Message Model](#message-model)\n- [Custom Message ID Generation](#custom-message-id-generation)\n- [Testing Guidelines](#testing-guidelines)\n- [Development Guidelines](#development-guidelines)\n- [Database Migration](#database-migration)\n\n## Message Model\n\nThe `Message` model is the core entity of the messaging service, located in `src/cnts_messaging_svc/models/message.py`. It uses a sophisticated composite primary key design that enables flexible message organization and scoped auto-increment functionality.\n\n### Schema Definition\n\nThe Message model contains the following fields:\n\n| Field | Type | Constraints | Description |\n|-------|------|-------------|-------------|\n| `topic_type` | String(255) | NOT NULL, PK | Categorizes the message topic (e.g., \"project\", \"task\") |\n| `topic_id` | String(255) | NOT NULL, PK | Unique identifier within topic type (e.g., \"123\", \"abc-def\") |\n| `message_type` | String(255) | NOT NULL, PK | Type of message (e.g., \"status_update\", \"comment\", \"notification\") |\n| `message_id` | BigInteger | NOT NULL, PK | Auto-incrementing ID scoped to topic combination |\n| `sender_type` | String(255) | NOT NULL | Type of sender (e.g., \"user\", \"system\", \"service\") |\n| `sender_id` | String(255) | NOT NULL | Unique identifier of the sender |\n| `content_type` | String(255) | NOT NULL | MIME type of content (e.g., \"text/plain\", \"application/json\") |\n| `content` | Text | NOT NULL | The actual message content |\n| `created_at` | TIMESTAMP with timezone | NOT NULL, Auto-generated | Creation timestamp |\n\n### Composite Primary Key\n\nThe Message model uses a four-field composite primary key: `(topic_type, topic_id, message_type, message_id)`\n\n**Benefits of this design:**\n- **Flexible Organization**: Messages are naturally grouped by topic and type\n- **Scoped Auto-increment**: Message IDs are sequential within each scope\n- **Efficient Querying**: Direct access to message sequences within topics\n- **Isolation**: Different topics and message types maintain independent numbering\n\n**Example:**\n```python\nfrom cnts_messaging_svc.models import Message\n\n# These messages can all have message_id=1 because they're in different scopes\nmsg1 = Message(topic_type=\"project\", topic_id=\"123\", message_type=\"status_update\", message_id=1, ...)\nmsg2 = Message(topic_type=\"project\", topic_id=\"456\", message_type=\"status_update\", message_id=1, ...)  # Different topic_id\nmsg3 = Message(topic_type=\"task\", topic_id=\"123\", message_type=\"status_update\", message_id=1, ...)     # Different topic_type\nmsg4 = Message(topic_type=\"project\", topic_id=\"123\", message_type=\"comment\", message_id=1, ...)        # Different message_type\n```\n\n## Custom Message ID Generation\n\nThe messaging service implements a sophisticated auto-increment mechanism that generates sequential `message_id` values within the scope of `(topic_type, topic_id, message_type)` combinations. The implementation differs between production (PostgreSQL) and development/testing (SQLite) environments.\n\n### PostgreSQL Production Environment\n\nFor production deployments using PostgreSQL, the auto-increment logic is implemented at the database level using stored functions and triggers.\n\n#### Database Function: `generate_message_id_for_topic`\n\n```sql\nCREATE OR REPLACE FUNCTION generate_message_id_for_topic(\n    p_topic_type VARCHAR, \n    p_topic_id VARCHAR, \n    p_message_type VARCHAR\n) RETURNS BIGINT AS $$\nBEGIN\n    RETURN COALESCE(\n        (\n            SELECT MAX(message_id) \n            FROM messages \n            WHERE topic_type = p_topic_type \n              AND topic_id = p_topic_id \n              AND message_type = p_message_type\n        ), 0\n    ) + 1;\nEND;\n$$ LANGUAGE plpgsql;\n```\n\n**Purpose**: Generates the next sequential `message_id` within the specified scope by finding the maximum existing `message_id` and adding 1.\n\n**Parameters**:\n- `p_topic_type`: The topic type to scope the search\n- `p_topic_id`: The topic ID to scope the search  \n- `p_message_type`: The message type to scope the search\n\n**Logic**: Uses `COALESCE(MAX(message_id), 0) + 1` to handle both existing sequences and first messages in a new scope.\n\n#### Database Trigger: `trigger_generate_message_id`\n\n```sql\nCREATE OR REPLACE FUNCTION trigger_generate_message_id() RETURNS TRIGGER AS $$\nBEGIN\n    IF NEW.message_id IS NULL THEN\n        NEW.message_id := generate_message_id_for_topic(\n            NEW.topic_type, \n            NEW.topic_id, \n            NEW.message_type\n        );\n    END IF;\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trigger_generate_message_id\nBEFORE INSERT ON messages\nFOR EACH ROW\nEXECUTE FUNCTION trigger_generate_message_id();\n```\n\n**Features**:\n- Executes `BEFORE INSERT` on the messages table\n- Only generates `message_id` when it's NULL (preserves explicit values)\n- Automatically calls the generation function\n- Ensures database-level consistency and optimal performance\n\n### SQLite Development/Testing Environment\n\nFor development and testing environments using SQLite, the auto-increment logic is implemented using SQLAlchemy event listeners since SQLite doesn't support the same stored procedure syntax as PostgreSQL.\n\n#### Event Listener: `generate_message_id_listener`\n\n```python\ndef generate_message_id_listener(mapper, connection, target):\n    \"\"\"Auto-generate message_id if not provided for SQLite and development environments.\n    \n    This event listener executes before insert operations on the Message model.\n    If message_id is None, it queries the database to find the next sequential\n    message_id within the scope of (topic_type, topic_id, message_type).\n    \"\"\"\n    if target.message_id is None:\n        try:\n            # Query for the maximum message_id in the current scope\n            result = connection.execute(\n                text(\"\"\"\n                SELECT COALESCE(MAX(message_id), 0) + 1 \n                FROM messages \n                WHERE topic_type = :topic_type \n                AND topic_id = :topic_id \n                AND message_type = :message_type\n                \"\"\"),\n                {\n                    \"topic_type\": target.topic_type,\n                    \"topic_id\": target.topic_id,\n                    \"message_type\": target.message_type\n                }\n            )\n            target.message_id = result.scalar()\n        except Exception as e:\n            logging.error(f\"Failed to generate message_id: {e}\", exc_info=True)\n            raise\n\n# Register the event listener\nevent.listen(Message, 'before_insert', generate_message_id_listener)\n```\n\n**Features**:\n- SQLAlchemy `before_insert` event handler\n- Programmatic message_id generation in Python\n- Same scoping logic as PostgreSQL version\n- Comprehensive error handling with logging\n\n**Why This Approach for SQLite**:\n- SQLite doesn't support PostgreSQL's stored procedure syntax\n- Event listeners provide equivalent functionality in the application layer\n- Maintains consistent behavior across environments\n\n**Trade-offs**:\n- **PostgreSQL**: Database-level atomicity, better performance for high concurrency\n- **SQLite**: Application-level logic, simpler deployment, adequate for development/testing\n\n### Message ID Scoping Examples\n\nThe scoping mechanism ensures that message IDs are unique within their scope but can be reused across different scopes:\n\n```python\n# Scope 1: project-123-status_update\nmsg1 = Message(topic_type=\"project\", topic_id=\"123\", message_type=\"status_update\")  # message_id=1\nmsg2 = Message(topic_type=\"project\", topic_id=\"123\", message_type=\"status_update\")  # message_id=2\nmsg3 = Message(topic_type=\"project\", topic_id=\"123\", message_type=\"status_update\")  # message_id=3\n\n# Scope 2: project-456-status_update (different topic_id)\nmsg4 = Message(topic_type=\"project\", topic_id=\"456\", message_type=\"status_update\")  # message_id=1\nmsg5 = Message(topic_type=\"project\", topic_id=\"456\", message_type=\"status_update\")  # message_id=2\n\n# Scope 3: task-123-status_update (different topic_type)\nmsg6 = Message(topic_type=\"task\", topic_id=\"123\", message_type=\"status_update\")    # message_id=1\n\n# Scope 4: project-123-comment (different message_type)\nmsg7 = Message(topic_type=\"project\", topic_id=\"123\", message_type=\"comment\")       # message_id=1\n```\n\n## Testing Guidelines\n\nThe messaging service provides comprehensive testing infrastructure to facilitate easy and effective testing of Message entities and the auto-increment mechanism.\n\n### Database Test Setup\n\n#### `create_all_tables` Function\n\nThe `create_all_tables` function from `src/cnts_messaging_svc/models/factories.py` handles automatic database schema creation:\n\n```python\nfrom cnts_messaging_svc.models.factories import create_all_tables\n\ndef create_all_tables(engine) -> None:\n    \"\"\"Create all database tables using Base metadata.\n    \n    Args:\n        engine: SQLAlchemy engine instance\n    \"\"\"\n    try:\n        Base.metadata.create_all(engine)\n    except Exception as e:\n        logging.error(f\"Failed to create tables: {e}\", exc_info=True)\n        raise\n```\n\n#### Integration with `conftest.py`\n\nThe function is automatically integrated into the test infrastructure via `tests/conftest.py`:\n\n```python\n@pytest.fixture\ndef session_local():\n    engine = create_engine('sqlite:///:memory:',\n                          connect_args={'check_same_thread': False},\n                          poolclass=StaticPool)\n    create_all_tables(engine)  # Automatic table creation\n    return sessionmaker(bind=engine)\n\n@pytest.fixture\ndef db_session(session_local):\n    session = session_local()\n    try:\n        yield session\n    finally:\n        session.close()\n```\n\n**Benefits**:\n- **Automatic Setup**: Tables are created automatically for each test session\n- **In-Memory Database**: Uses SQLite in-memory for fast, isolated tests\n- **Clean State**: Each test gets a fresh database state\n\n### MessageDataFactory Usage\n\nThe `MessageDataFactory` provides a flexible factory for creating test Message instances:\n\n```python\nfrom cnts_messaging_svc.models.factories import MessageDataFactory\n\ndef MessageDataFactory(\n    topic_type: str = \"test_project\",\n    topic_id: str = \"123\",\n    message_type: str = \"status_update\",\n    message_id: Optional[int] = None,\n    sender_type: str = \"user\",\n    sender_id: str = \"test_user\",\n    content_type: str = \"text/plain\",\n    content: str = \"Test message content\",\n    **kwargs\n) -> Message:\n```\n\n#### Factory Parameters and Defaults\n\n| Parameter | Default Value | Description |\n|-----------|---------------|-------------|\n| `topic_type` | \"test_project\" | Topic type for the message |\n| `topic_id` | \"123\" | Topic ID for the message |\n| `message_type` | \"status_update\" | Type of message |\n| `message_id` | `None` | Message ID (auto-generated if None) |\n| `sender_type` | \"user\" | Type of sender |\n| `sender_id` | \"test_user\" | Sender identifier |\n| `content_type` | \"text/plain\" | Content MIME type |\n| `content` | \"Test message content\" | Message content |\n\n#### Basic Usage Examples\n\n```python\ndef test_basic_message_creation(db_session):\n    \"\"\"Test creating a message with default factory values.\"\"\"\n    message = MessageDataFactory()\n    \n    db_session.add(message)\n    db_session.commit()\n    \n    # message_id will be auto-generated as 1\n    assert message.message_id == 1\n    assert message.topic_type == \"test_project\"\n    assert message.content == \"Test message content\"\n\ndef test_custom_message_creation(db_session):\n    \"\"\"Test creating a message with custom values.\"\"\"\n    message = MessageDataFactory(\n        topic_type=\"custom_project\",\n        topic_id=\"456\",\n        message_type=\"notification\",\n        content=\"Custom test message\"\n    )\n    \n    db_session.add(message)\n    db_session.commit()\n    \n    assert message.topic_type == \"custom_project\"\n    assert message.topic_id == \"456\"\n    assert message.message_type == \"notification\"\n    assert message.content == \"Custom test message\"\n\ndef test_explicit_message_id(db_session):\n    \"\"\"Test creating a message with explicit message_id.\"\"\"\n    message = MessageDataFactory(\n        message_id=42,\n        content=\"Explicit ID message\"\n    )\n    \n    db_session.add(message)\n    db_session.commit()\n    \n    # Explicit message_id should be preserved\n    assert message.message_id == 42\n```\n\n#### Advanced Usage with kwargs\n\n```python\ndef test_kwargs_override(db_session):\n    \"\"\"Test using kwargs to override specific fields.\"\"\"\n    message = MessageDataFactory(\n        sender_type=\"system\",\n        content_type=\"application/json\",\n        invalid_field=\"ignored\"  # Invalid fields are ignored\n    )\n    \n    assert message.sender_type == \"system\"\n    assert message.content_type == \"application/json\"\n    # invalid_field is silently ignored\n```\n\n### Testing Patterns and Best Practices\n\n#### Using the db_session Fixture\n\nAlways use the `db_session` fixture from `conftest.py` for database operations:\n\n```python\ndef test_message_operations(db_session):\n    \"\"\"Example of proper db_session usage.\"\"\"\n    # Create and insert message\n    message = MessageDataFactory(content=\"Test message\")\n    db_session.add(message)\n    db_session.commit()\n    \n    # Query the message\n    from sqlalchemy import select\n    stmt = select(Message).where(Message.message_id == message.message_id)\n    result = db_session.execute(stmt)\n    retrieved = result.scalar_one_or_none()\n    \n    assert retrieved is not None\n    assert retrieved.content == \"Test message\"\n```\n\n#### Testing Auto-Increment Behavior\n\n```python\ndef test_auto_increment_sequence(db_session):\n    \"\"\"Test sequential message_id generation.\"\"\"\n    messages = []\n    \n    # Create multiple messages in the same scope\n    for i in range(3):\n        message = MessageDataFactory(\n            content=f\"Message {i+1}\"\n        )\n        messages.append(message)\n        db_session.add(message)\n        db_session.commit()\n    \n    # Verify sequential numbering\n    assert messages[0].message_id == 1\n    assert messages[1].message_id == 2\n    assert messages[2].message_id == 3\n```\n\n#### Testing Scope Isolation\n\n```python\ndef test_scope_isolation(db_session):\n    \"\"\"Test message_id isolation across different scopes.\"\"\"\n    # Create messages in different scopes\n    msg1 = MessageDataFactory(\n        topic_type=\"project\", topic_id=\"123\", message_type=\"status\"\n    )\n    msg2 = MessageDataFactory(\n        topic_type=\"project\", topic_id=\"456\", message_type=\"status\"\n    )\n    msg3 = MessageDataFactory(\n        topic_type=\"task\", topic_id=\"123\", message_type=\"status\"\n    )\n    \n    db_session.add_all([msg1, msg2, msg3])\n    db_session.commit()\n    \n    # All should have message_id=1 due to scope isolation\n    assert msg1.message_id == 1\n    assert msg2.message_id == 1\n    assert msg3.message_id == 1\n```\n\n#### Testing Error Scenarios\n\n```python\ndef test_duplicate_primary_key_error(db_session):\n    \"\"\"Test that duplicate composite keys raise IntegrityError.\"\"\"\n    import pytest\n    from sqlalchemy.exc import IntegrityError\n    \n    # Create first message\n    msg1 = MessageDataFactory(message_id=1)\n    db_session.add(msg1)\n    db_session.commit()\n    \n    # Try to create duplicate\n    msg2 = MessageDataFactory(message_id=1)  # Same composite key\n    db_session.add(msg2)\n    \n    with pytest.raises(IntegrityError):\n        db_session.commit()\n```\n\n## Development Guidelines\n\n### Creating New Messages\n\n#### Programmatic Message Creation\n\n```python\nfrom cnts_messaging_svc.models import Message\nfrom cnts_messaging_svc.models.base import get_db\n\ndef create_message_example():\n    \"\"\"Example of creating a message programmatically.\"\"\"\n    with next(get_db()) as session:\n        message = Message(\n            topic_type=\"project\",\n            topic_id=\"abc-123\",\n            message_type=\"status_update\",\n            # message_id intentionally omitted for auto-generation\n            sender_type=\"user\",\n            sender_id=\"john_doe\",\n            content_type=\"text/plain\",\n            content=\"Project has been updated with new requirements\"\n        )\n        \n        session.add(message)\n        session.commit()\n        \n        print(f\"Created message with ID: {message.message_id}\")\n```\n\n#### When to Specify message_id vs Auto-Generate\n\n**Auto-generate (Recommended)**:\n- Most common use case\n- Ensures sequential numbering\n- Prevents conflicts\n- Omit `message_id` or set to `None`\n\n```python\n# Auto-generate message_id\nmessage = Message(\n    topic_type=\"project\",\n    topic_id=\"123\",\n    message_type=\"comment\",\n    # message_id omitted - will be auto-generated\n    sender_type=\"user\",\n    sender_id=\"alice\",\n    content_type=\"text/plain\",\n    content=\"This is a comment\"\n)\n```\n\n**Explicit message_id**:\n- Data migration scenarios\n- Importing from external systems\n- Testing specific edge cases\n- When you need predictable IDs\n\n```python\n# Explicit message_id for data migration\nmessage = Message(\n    topic_type=\"legacy_project\",\n    topic_id=\"old_123\",\n    message_type=\"imported_comment\",\n    message_id=9999,  # Explicit ID from legacy system\n    sender_type=\"user\",\n    sender_id=\"legacy_user\",\n    content_type=\"text/plain\",\n    content=\"Migrated comment from old system\"\n)\n```\n\n### Querying Messages\n\n#### Querying by Composite Primary Key\n\n```python\nfrom sqlalchemy import select\nfrom cnts_messaging_svc.models import Message\n\ndef find_specific_message(session, topic_type, topic_id, message_type, message_id):\n    \"\"\"Find a specific message by its composite primary key.\"\"\"\n    stmt = select(Message).where(\n        Message.topic_type == topic_type,\n        Message.topic_id == topic_id,\n        Message.message_type == message_type,\n        Message.message_id == message_id\n    )\n    result = session.execute(stmt)\n    return result.scalar_one_or_none()\n```\n\n#### Efficient Query Patterns\n\n```python\ndef get_topic_messages(session, topic_type, topic_id, message_type=None, limit=50):\n    \"\"\"Get messages for a specific topic, optionally filtered by message_type.\"\"\"\n    stmt = select(Message).where(\n        Message.topic_type == topic_type,\n        Message.topic_id == topic_id\n    )\n    \n    if message_type:\n        stmt = stmt.where(Message.message_type == message_type)\n    \n    stmt = stmt.order_by(Message.message_id.desc()).limit(limit)\n    \n    result = session.execute(stmt)\n    return result.scalars().all()\n\ndef get_latest_message_in_scope(session, topic_type, topic_id, message_type):\n    \"\"\"Get the most recent message in a specific scope.\"\"\"\n    stmt = select(Message).where(\n        Message.topic_type == topic_type,\n        Message.topic_id == topic_id,\n        Message.message_type == message_type\n    ).order_by(Message.message_id.desc()).limit(1)\n    \n    result = session.execute(stmt)\n    return result.scalar_one_or_none()\n\ndef count_messages_in_topic(session, topic_type, topic_id):\n    \"\"\"Count total messages in a topic across all message types.\"\"\"\n    from sqlalchemy import func\n    \n    stmt = select(func.count(Message.message_id)).where(\n        Message.topic_type == topic_type,\n        Message.topic_id == topic_id\n    )\n    \n    result = session.execute(stmt)\n    return result.scalar()\n```\n\n#### Common Query Scenarios\n\n```python\n# Get all status updates for a project\nstatus_updates = get_topic_messages(\n    session, \"project\", \"123\", \"status_update\"\n)\n\n# Get latest comment in a discussion\nlatest_comment = get_latest_message_in_scope(\n    session, \"discussion\", \"thread_456\", \"comment\"\n)\n\n# Get recent messages across all types\nrecent_messages = get_topic_messages(\n    session, \"project\", \"123\", limit=10\n)\n```\n\n### Best Practices for Message Content and Metadata\n\n#### Content Guidelines\n\n```python\n# Good: Structured content with appropriate content_type\nmessage = Message(\n    topic_type=\"project\",\n    topic_id=\"123\",\n    message_type=\"status_update\",\n    sender_type=\"user\",\n    sender_id=\"john_doe\",\n    content_type=\"application/json\",\n    content=json.dumps({\n        \"status\": \"in_progress\",\n        \"completion_percentage\": 75,\n        \"notes\": \"Backend API implementation completed\"\n    })\n)\n\n# Good: Plain text with clear content_type\nmessage = Message(\n    topic_type=\"support\",\n    topic_id=\"ticket_456\",\n    message_type=\"customer_message\",\n    sender_type=\"user\",\n    sender_id=\"customer_789\",\n    content_type=\"text/plain\",\n    content=\"I'm experiencing issues with login functionality.\"\n)\n```\n\n#### Metadata Best Practices\n\n- **topic_type**: Use consistent naming (lowercase, underscores)\n- **topic_id**: Use meaningful identifiers (UUIDs, natural keys)\n- **message_type**: Be specific and descriptive\n- **sender_type**: Categorize senders meaningfully\n- **content_type**: Use proper MIME types\n\n## Database Migration\n\nThe Message model and its auto-increment mechanism are managed through Alembic migrations.\n\n### Current Migration: `7ec50afff420`\n\nThe initial migration (`migrations/versions/7ec50afff420_create_message_model_and_add_custom_.py`) handles:\n\n1. **Table Creation**: Creates the `messages` table with composite primary key\n2. **Environment Detection**: Checks database dialect (PostgreSQL vs SQLite)\n3. **PostgreSQL Setup**: Creates functions and triggers for auto-increment\n4. **Rollback Support**: Properly removes all database objects on downgrade\n\n### Migration Features\n\n#### Environment-Aware Migration\n\n```python\n# Check if we're running on PostgreSQL\nbind = op.get_bind()\nif bind.dialect.name == 'postgresql':\n    # Create PostgreSQL-specific objects\n    op.execute(sa.text(\"CREATE OR REPLACE FUNCTION generate_message_id_for_topic...\"))\nelse:\n    # SQLite uses event listeners (no database objects needed)\n    pass\n```\n\n#### Safe Rollback\n\n```python\ndef downgrade() -> None:\n    # Check if we're running on PostgreSQL\n    bind = op.get_bind()\n    if bind.dialect.name == 'postgresql':\n        # Drop trigger first, then function (correct order)\n        op.execute(sa.text(\"DROP TRIGGER IF EXISTS trigger_generate_message_id ON messages;\"))\n        op.execute(sa.text(\"DROP FUNCTION IF EXISTS trigger_generate_message_id();\"))\n        op.execute(sa.text(\"DROP FUNCTION IF EXISTS generate_message_id_for_topic(VARCHAR, VARCHAR, VARCHAR);\"))\n    \n    op.drop_table('messages')\n```\n\n### Running Migrations\n\n```bash\n# Apply migrations\nmake setup\n# or\npoetry run alembic upgrade head\n\n# Check migration status\npoetry run alembic current\n\n# Rollback (if needed)\npoetry run alembic downgrade -1\n```\n\n### Migration Considerations\n\n- **Data Preservation**: The auto-increment mechanism preserves existing message sequences\n- **Environment Compatibility**: Same migration works for both PostgreSQL and SQLite\n- **Zero Downtime**: PostgreSQL functions and triggers are created with `CREATE OR REPLACE`\n- **Rollback Safety**: All objects are dropped safely with `IF EXISTS` clauses\n\n## Troubleshooting\n\n### Common Issues\n\n#### Message ID Generation Failures\n\n**Symptoms**: `message_id` remains `None` after insert\n\n**Solutions**:\n1. Check that event listener is registered (SQLite)\n2. Verify trigger exists (PostgreSQL): `SELECT * FROM information_schema.triggers WHERE trigger_name = 'trigger_generate_message_id';`\n3. Check database connection and permissions\n\n#### Duplicate Primary Key Errors\n\n**Symptoms**: `IntegrityError` on message insert\n\n**Solutions**:\n1. Verify scope parameters (topic_type, topic_id, message_type)\n2. Check for explicit message_id conflicts\n3. Ensure auto-increment is working properly\n\n#### Performance Issues\n\n**Symptoms**: Slow message insertion or querying\n\n**Solutions**:\n1. Add indexes on frequently queried fields:\n   ```sql\n   CREATE INDEX idx_messages_topic ON messages(topic_type, topic_id);\n   CREATE INDEX idx_messages_created_at ON messages(created_at);\n   ```\n2. Use appropriate query limits for large datasets\n3. Consider message archiving strategies for high-volume topics\n\n---\n\n## Contributing\n\nWhen working with the Message model:\n\n1. **Always use the factories** for testing\n2. **Follow the composite key design** - don't add surrogate keys\n3. **Test both environments** if making changes to auto-increment logic\n4. **Update documentation** when adding new message types or fields\n5. **Consider migration impact** for schema changes\n\nFor questions or issues, refer to the comprehensive test suite in `tests/test_message_model.py` for examples and patterns.